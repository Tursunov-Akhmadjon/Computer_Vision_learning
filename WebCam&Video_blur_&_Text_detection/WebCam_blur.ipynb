{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"16VKneQKVuvHzWHd8WQK18iC5KI5ZaSRY","authorship_tag":"ABX9TyNS97aFz8A1aRO59YJ4e+xM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3wZjqhTJ8aPG"},"outputs":[],"source":["import cv2\n","import mediapipe as mp\n","\n","# Initialize the face detection model from Mediapipe\n","mp_face_detection = mp.solutions.face_detection\n","face_detection = mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5)\n","\n","# Open the webcam\n","cap = cv2.VideoCapture(0)\n","\n","# Check if the webcam was opened successfully\n","if not cap.isOpened():\n","    print(\"Error: Couldn't open the cam\")\n","    exit(1)\n","\n","# Inform the user how to exit the program\n","print(\"Press 'q' to exit\")\n","\n","# Start a loop to continuously capture video frames\n","while True:\n","    sucsess, frame = cap.read()  # Capture a frame from the webcam\n","    if not sucsess:\n","        break\n","\n","    # Convert the frame from BGR to RGB color format\n","    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","\n","    # Process the frame for face detection using the Mediapipe face detection model\n","    results = face_detection.process(frame_rgb)\n","\n","    # Check if any faces were detected\n","    if results.detections:\n","        for detection in results.detections:\n","            # Extract the bounding box coordinates of the detected face\n","            bboxC = detection.location_data.relative_bounding_box\n","            h, w, _ = frame.shape\n","\n","            # Calculate the x, y, width, and height of the bounding box in pixel values\n","            x, y, width, height = (int(bboxC.xmin * w), int(bboxC.ymin * h),\n","                                   int(bboxC.width * w), int(bboxC.height * h))\n","\n","            # Ensure the coordinates do not go out of frame bounds\n","            x, y = max(0, x), max(0, y)\n","            width, height = min(w - x, width), min(h - y, height)\n","\n","            # Extract the region of the frame corresponding to the detected face\n","            face_region = frame[y:y+height, x:x+width]\n","\n","            # Apply a Gaussian blur to the face region\n","            blurred_face = cv2.GaussianBlur(face_region, (55, 55), 10)\n","\n","            # Replace the original face region in the frame with the blurred version\n","            frame[y:y+height, x:x+width] = blurred_face\n","\n","    # Display the processed frame with the blurred face\n","    cv2.imshow(\"Face Blur Webcam(MediaPipe)\", frame)\n","\n","    # Check if the user pressed the 'q' key to exit the loop\n","    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n","        break\n","\n","# Release the video capture object and close the OpenCV windows\n","cap.release()\n","cv2.destroyAllWindows()\n"]}]}