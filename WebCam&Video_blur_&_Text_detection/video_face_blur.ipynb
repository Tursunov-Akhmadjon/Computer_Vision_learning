{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1nOhpoTLeyuQjSRUmMz3PpscRcZSQIoW8","authorship_tag":"ABX9TyP0mP2zr7/DNrF+/qtgEWtx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1Acg1h4j_dfjCExNIqWzBuq0-QYCMbB4Z"},"id":"Dnhz1eUuAwN3","executionInfo":{"status":"ok","timestamp":1741409471244,"user_tz":-540,"elapsed":88475,"user":{"displayName":"Axmadjon Tursunov","userId":"03712543799512781896"}},"outputId":"82cee788-6ff5-444a-e3af-104cca3624ff"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import cv2\n","import mediapipe as mp\n","import os\n","from google.colab.patches import cv2_imshow\n","\n","\n","# Input video path\n","input_video = \"/content/drive/MyDrive/Colab Notebooks/Computer Vision/WebCam&Video_blur_&_Text_detection/face_detect_video.mp4\"\n","# Output directory to save the processed video\n","output_dir = \"/content/drive/MyDrive/Colab Notebooks/Computer Vision/WebCam&Video_blur_&_Text_detection/output\"\n","\n","# Create the output directory if it doesn't exist\n","os.makedirs(output_dir, exist_ok=True)\n","output_video = os.path.join(output_dir, \"blured_face_video.mp4\")\n","\n","# Check if the input video file exists\n","if not os.path.exists(input_video):\n","    print(\"Error: Video not found\")\n","    exit(1)\n","\n","# Initialize Mediapipe face detection model\n","mp_face = mp.solutions.face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5)\n","\n","# Open the video file for reading\n","cap = cv2.VideoCapture(input_video)\n","\n","# Check if the video file was opened successfully\n","if not cap.isOpened():\n","    print(\"Error: Could not open video file\")\n","    exit(1)\n","\n","# Get the width, height, and frames\n","frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) * 0.50)  # Resize frame width to 50% of original\n","frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) * 0.50)  # Resize frame height to 50% of original\n","fps = int(cap.get(cv2.CAP_PROP_FPS))  # Get the frames per second of the video\n","\n","\n","fourcc = cv2.VideoWriter_fourcc(*\"MP4V\")\n","out = cv2.VideoWriter(output_video, fourcc, fps, (frame_width, frame_height))\n","\n","# Process the video frame by frame\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    # Resize the frame to reduce processing time\n","    frame = cv2.resize(frame, (frame_width, frame_height))\n","\n","    # Convert the frame from BGR to RGB for face detection\n","    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","    results = mp_face.process(frame_rgb)  # Detect faces in the frame\n","\n","    # If faces are detected in the frame\n","    if results.detections:\n","        for detection in results.detections:\n","            # Get the bounding box coordinates for the detected face\n","            bbox = detection.location_data.relative_bounding_box\n","            x, y, w, h = (\n","                int(bbox.xmin * frame_width), int(bbox.ymin * frame_height),\n","                int(bbox.width * frame_width), int(bbox.height * frame_height)\n","            )\n","\n","            # Add a little padding around the detected face\n","            x, y = max(0, x - 10), max(0, y - 10)\n","            w, h = min(frame_width - x, w + 20), min(frame_height - y, h + 20)\n","\n","\n","            face_roi = frame[y:y+h, x:x+w]\n","\n","            # Apply Gaussian blur to the face region\n","            if face_roi.shape[0] > 0 and face_roi.shape[1] > 0:\n","                blured_face = cv2.GaussianBlur(face_roi, (55, 55), 30)\n","                frame[y:y+h, x:x+w] = blured_face\n","\n","    # Write the modified frame to the output video file\n","    out.write(frame)\n","\n","    # Display the current fram\n","    cv2_imshow(frame) #(for google colab:cv2_imshow)\n","\n","    # Exit the loop if 'q' is pressed\n","    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n","        break\n","\n","# Release the video capture and output video objects\n","cap.release()\n","out.release()\n","\n","# Close any OpenCV windows\n","cv2.destroyAllWindows()\n","\n","# Print a message\n","print(f\"Blurred face video saved at {output_video}\")\n"]}]}